# [일일 업무 보고서] 워크스페이스 정비 및 소프트웨어 아키텍처 수립

**작성일:** 2026년 2월 2일 (월)
**주제:** 워크스페이스 정비 및 소프트웨어 아키텍처(4+1 View) 수립

---

## 1. 워크스페이스 정리
**물리적 환경 구축:**
* 냉장고 내부 선반 위치 고정
* 로봇 작업 반경을 고려한 냉장고 배치 위치 고정

## 2. 소프트웨어 아키텍처 4+1 뷰(View) 개념 학습
시스템의 다양한 이해관계자(Stakeholders)의 관점을 반영하기 위한 4+1 View 모델의 개념과 구성요소를 학습함.

| 뷰(View) | 대상 (Target) | 내용 (Content) | 관심사 (Concerns) |
| :--- | :--- | :--- | :--- |
| **논리뷰 (Logical View)** | 설계자, 개발자 | 시스템의 기능적 요구사항 | 시스템이 제공하는 주요 서비스와 기능 |
| **구현뷰 (Implementation View)** | 프로그래머 | SW 모듈, 라이브러리, 서브시스템 | SW 구성요소 간 의존성, 재사용성 |
| **프로세스뷰 (Process View)** | 시스템 통합자 | 시스템 동적 측면, 프로세스 간 통신 | 병렬처리, 동시성, 성능, 확장성 |
| **배포뷰 (Deployment View)** | 시스템 엔지니어, 인프라 담당자 | 물리적 노드와 SW 컴포넌트 매핑 | 분산 시스템의 물리적 배치, 하드웨어 요구사항 |
| **유스케이스 뷰 (Use-case View)** | 최종 사용자, 고객, 기획자 | 시스템 행위/기능에 대한 시나리오 | 비즈니스 문제 해결, 사용자 요구사항 검증 |

## 3. 프로젝트 아키텍처 수립 (4+1 View 적용)

### 3-1. 논리뷰 (Logical View)
* **주요 기능:** 주문 처리(Order Handling), 레시피 관리(Recipe Management), 환경 인식(Perception), 작업 제어(Task Control), 상태 감시(System Monitoring)
* **클래스(노드) 구조:**
    * 로봇팔 Bringup 노드
    * 카메라 Realsense 연결 노드
    * `pick_and_place` 노드 (메인 제어)
    * `detect` 노드 (객체 인식)
    * `get_keyword` 노드 (음성 인식)
    * `describer` 노드 (상태 기술)
* **세부 명세:**
    * **도메인 모델:** 레시피(사과, 라면), 인식된 물체(냄비, 후라이팬)
    * **인터페이스 정의:**
        * `/pick_and_place` → 로봇팔 (DSR_ROBOT2 API)
        * `/pick_and_place` → `/describer` (`/cocooker_control_status`)
        * `/pick_and_place` → `/detect` (`/get_3d_position`)
        * `/pick_and_place` → `/get_keyword` (`/get_keyword`)
        * `/detect` → `/describer` (`/cocooker_detect_status`)
    * **상태관리 로직 (미구현/계획):** Idle → OrderReceived → Scanning → Cooking → Done

### 3-2. 구현뷰 (Implementation View)
* **설계 원칙:** 모듈 간 의존성을 낮추기 위해 통신 메시지(interfaces)를 별도 패키지로 분리하고, 하드웨어 제어(Control)와 인지(Vision) 기능을 독립적인 패키지로 구성하여 개별 빌드 및 테스트가 가능하도록 설계함.
* **패키지 및 디렉터리 구조:**
    * `cobot_ws/src/`
        * `od_msg` (Interface Package)
            * `CMakeLists.txt`, `package.xml`, `srv/SrvDepthPosition.srv`
        * `pick_and_place_voice` (Main Package)
            * `describer/`, `object_detection/`, `resource/`, `robot_control/`, `voice_processing/`
            * `package.xml`, `setup.py`
* **컴포넌트 의존성 및 빌드 환경:**
    * **설치 순서:** Interface (ROS2, od_msgs) → Vision (CV, YOLO) → Control (DSR_ROBOT2)
    * **OS & Platform:** Ubuntu 22.04.5 LTS
    * **ROS Version:** ROS 2 Humble Hawksbill
    * **Language:** Python 3.10.12 (C++ 11/14 호환)
    * **Build Tool:** `colcon build --symlink-install`
    * **Third-party:** Doosan Robotics (dsr_robot2), Intel RealSense SDK 2.0

### 3-3. 프로세스뷰 (Process View)
* **프로세스 목록 및 역할:**
    * `get_keyword` (Event-driven): 마이크 입력 대기 후 음성 감지 시 활성화.
    * `robot_control` (Periodic + Event): 메인 루프 상태 관리 및 명령 반응.
    * `object_detection` (Service-based): 요청 시 연산 수행 (또는 30fps 감지).
    * `describer` (Periodic): 1초 주기 전체 노드 생존 확인.
* **프로세스 간 통신 (제어 및 데이터 흐름):**
    * **음성 명령 요청:** `robot_control` → `/get_keyword` (Service) → 마이크 Wake-up → STT/LLM → 키워드 반환.
    * **좌표 변환 요청:** `robot_control` → `/get_3d_position` (Service) → `object_detection` (Target 전송 → YOLO/Depth 계산 → XYZ 반환).
    * **상태 모니터링 (비동기 Topic):** 메인 로직 Blocking 여부와 관계없이 별도 스레드에서 Heartbeat 발행 (1.0초 주기).
* **동시성 및 스레드 모델 (Concurrency Strategy):**
    * **A. Robot Control Node (이중 스레드 전략):** Main Thread는 작업 수행 및 서비스 응답 대기(Blocking), Background Thread는 `executor.spin()`을 데몬 스레드로 실행하여 Timer/Callback 처리.
    * **B. Object Detection Node (재진입성 전략):** `ReentrantCallbackGroup`을 사용하여 무거운 YOLO 연산 중에도 Heartbeat Timer가 병렬 실행되도록 허용.

### 3-4. 배포뷰 (Deployment View)
* **하드웨어 구성요소:** 로봇팔(Doosan Robotics M0609), 센서(RGB-Depth 카메라 RealSense D435i with IMU), 연산 장치(Main PC)
* **네트워크 및 인터페이스 설정:** 로봇 연결(Ethernet/TCP/IP), 카메라 연결(USB 3.0), 그리퍼 연결(I/O Interface)

### 3-5. 유스케이스 뷰 (Use-case View)
* **목적:** 개발 범위 확정, 테스트 시나리오 도출 및 아키텍처 검증.
* **주요 시나리오:** 사용자 인식 → 요리 메뉴 선정 → 요리 준비 → 요리 마무리.

### 4.레퍼런스
* **commit:**
* **src:**
  * [Workspace Setup (Physical Environment)](../../src/Project_CV_Motion/2026_02_02_1_Workspace_Physical_Setup.png)
  * [Logical View (Functional Architecture)](../../src/Project_CV_Motion/2026_02_02_2_Logical_View_Architecture.svg)
  * [Deployment View (Network Topology)](../../src/Project_CV_Motion/2026_02_02_3_Deployment_View_Network_Topology.svg)
  * [Process View (Concurrency Model)](../../src/Project_CV_Motion/2026_02_02_4_Process_View_Concurrency_Strategy.png)
  * [Use-case View (Scenarios)](../../src/Project_CV_Motion/2026_02_02_5_Usecase_View_Scenario.svg)

**참고 자료:** 4+1 View 이해관계자 중심의 아키텍처 표현모델
  -4+1View 이해관계자 중심의 아키텍쳐 표현모델
  https://rupijun.tistory.com/entry/41-View-%EC%9D%B4%ED%95%B4%EA%B4%80%EA%B3%84%EC%9E%90-%EC%A4%91%EC%8B%AC%EC%9D%98-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98-%ED%91%9C%ED%98%84-%EB%AA%A8%EB%8D%B8
